{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6054558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define the directory where the processed data and feature sets are stored\n",
    "# This should match the path used in the preprocessing notebook\n",
    "data_dir = Path(\"processed_data\")\n",
    "\n",
    "# Load the preprocessed training and test datasets\n",
    "# These were created in the preprocessing notebook as train.csv and test.csv\n",
    "train_df = pd.read_csv(data_dir / \"train.csv\")\n",
    "test_df = pd.read_csv(data_dir / \"test.csv\")\n",
    "\n",
    "# Load the feature name sets (all_features, selected_features, etc.)\n",
    "# The JSON file contains four different feature lists and the target_features\n",
    "with open(data_dir / \"feature_sets.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    feature_sets = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4266ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['URLLength', 'DomainLength', 'IsDomainIP', 'URLSimilarityIndex', 'TLDLength', 'NoOfSubDomain', 'HasObfuscation', 'NoOfObfuscatedChar', 'ObfuscationRatio', 'NoOfLettersInURL', 'LetterRatioInURL', 'NoOfDegitsInURL', 'DegitRatioInURL', 'NoOfEqualsInURL', 'NoOfQMarkInURL', 'NoOfAmpersandInURL', 'NoOfOtherSpecialCharsInURL', 'SpacialCharRatioInURL', 'IsHTTPS', 'LineOfCode', 'LargestLineLength', 'HasTitle', 'DomainTitleMatchScore', 'HasFavicon', 'Robots', 'IsResponsive', 'NoOfURLRedirect', 'NoOfSelfRedirect', 'HasDescription', 'NoOfPopup', 'NoOfiFrame', 'HasExternalFormSubmit', 'HasSocialNet', 'HasSubmitButton', 'HasHiddenFields', 'HasPasswordField', 'Bank', 'Pay', 'Crypto', 'HasCopyrightInfo', 'NoOfImage', 'NoOfCSS', 'NoOfJS', 'NoOfSelfRef', 'NoOfEmptyRef', 'NoOfExternalRef', 'TLD'] ['URLSimilarityIndex', 'HasSocialNet', 'HasCopyrightInfo', 'HasDescription', 'IsHTTPS', 'DomainTitleMatchScore', 'HasSubmitButton', 'IsResponsive', 'HasHiddenFields', 'HasFavicon', 'HasTitle', 'DegitRatioInURL', 'SpacialCharRatioInURL', 'TLD']\n"
     ]
    }
   ],
   "source": [
    "all_features = feature_sets[\"all_features\"]\n",
    "features_without_targets = feature_sets[\"features_without_targets\"]\n",
    "selected_features = feature_sets[\"selected_features\"]\n",
    "selected_features_without_targets = feature_sets[\"selected_features_without_targets\"]\n",
    "\n",
    "target_column = \"label\"\n",
    "\n",
    "print(features_without_targets, selected_features_without_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25eb2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_map = {\n",
    "    \"all_features\": all_features,\n",
    "    \"features_without_targets\": features_without_targets,\n",
    "    \"selected_features\": selected_features,\n",
    "    \"selected_features_without_targets\": selected_features_without_targets,\n",
    "}\n",
    "\n",
    "# use a function to get data from different feature sets\n",
    "def get_data(feature_set_name: str):\n",
    "    feature_names = feature_set_map[feature_set_name]\n",
    "\n",
    "    X_train = train_df[feature_names]\n",
    "    X_test = test_df[feature_names]\n",
    "    y_train = train_df[target_column]\n",
    "    y_test = test_df[target_column]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222d4432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[#####---------------] 1/4  feature_set = all_features\n",
      "CV results (sorted by mean_test_score):\n",
      " param_classifier__C param_classifier__class_weight  mean_test_score  std_test_score\n",
      "                10.0                       balanced         0.999897        0.000028\n",
      "                 1.0                       balanced         0.999892        0.000031\n",
      "                10.0                           None         0.999881        0.000041\n",
      "                 1.0                           None         0.999875        0.000033\n",
      "                 0.1                       balanced         0.999816        0.000031\n",
      "                 0.1                           None         0.999783        0.000043\n",
      "Best params: {'classifier__C': 10.0, 'classifier__class_weight': 'balanced'}\n",
      "Test metrics -> accuracy: 0.999894, precision_macro: 0.999907, recall_macro: 0.999876, f1_macro: 0.999892\n",
      "\n",
      "[##########----------] 2/4  feature_set = features_without_targets\n",
      "CV results (sorted by mean_test_score):\n",
      " param_classifier__C param_classifier__class_weight  mean_test_score  std_test_score\n",
      "                10.0                       balanced         0.999908        0.000020\n",
      "                10.0                           None         0.999897        0.000015\n",
      "                 1.0                       balanced         0.999854        0.000048\n",
      "                 1.0                           None         0.999832        0.000033\n",
      "                 0.1                       balanced         0.999789        0.000048\n",
      "                 0.1                           None         0.999767        0.000041\n",
      "Best params: {'classifier__C': 10.0, 'classifier__class_weight': 'balanced'}\n",
      "Test metrics -> accuracy: 0.999915, precision_macro: 0.999926, recall_macro: 0.999901, f1_macro: 0.999913\n",
      "\n",
      "[###############-----] 3/4  feature_set = selected_features\n",
      "CV results (sorted by mean_test_score):\n",
      " param_classifier__C param_classifier__class_weight  mean_test_score  std_test_score\n",
      "                10.0                       balanced         0.999827        0.000054\n",
      "                10.0                           None         0.999816        0.000055\n",
      "                 1.0                       balanced         0.999789        0.000061\n",
      "                 1.0                           None         0.999773        0.000048\n",
      "                 0.1                       balanced         0.999637        0.000038\n",
      "                 0.1                           None         0.999578        0.000048\n",
      "Best params: {'classifier__C': 10.0, 'classifier__class_weight': 'balanced'}\n",
      "Test metrics -> accuracy: 0.999809, precision_macro: 0.999827, recall_macro: 0.999783, f1_macro: 0.999805\n",
      "\n",
      "[####################] 4/4  feature_set = selected_features_without_targets\n",
      "CV results (sorted by mean_test_score):\n",
      " param_classifier__C param_classifier__class_weight  mean_test_score  std_test_score\n",
      "                10.0                       balanced         0.999805        0.000023\n",
      "                10.0                           None         0.999800        0.000020\n",
      "                 1.0                       balanced         0.999783        0.000020\n",
      "                 1.0                           None         0.999783        0.000008\n",
      "                 0.1                       balanced         0.999626        0.000061\n",
      "                 0.1                           None         0.999578        0.000046\n",
      "Best params: {'classifier__C': 10.0, 'classifier__class_weight': 'balanced'}\n",
      "Test metrics -> accuracy: 0.999809, precision_macro: 0.999833, recall_macro: 0.999777, f1_macro: 0.999805\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_set</th>\n",
       "      <th>best_params</th>\n",
       "      <th>cv_best_score_f1_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_features</td>\n",
       "      <td>{\"classifier__C\": 10.0, \"classifier__class_wei...</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>features_without_targets</td>\n",
       "      <td>{\"classifier__C\": 10.0, \"classifier__class_wei...</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>selected_features</td>\n",
       "      <td>{\"classifier__C\": 10.0, \"classifier__class_wei...</td>\n",
       "      <td>0.999827</td>\n",
       "      <td>0.999809</td>\n",
       "      <td>0.999827</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.999805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>selected_features_without_targets</td>\n",
       "      <td>{\"classifier__C\": 10.0, \"classifier__class_wei...</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.999809</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature_set  \\\n",
       "0                       all_features   \n",
       "1           features_without_targets   \n",
       "2                  selected_features   \n",
       "3  selected_features_without_targets   \n",
       "\n",
       "                                         best_params  cv_best_score_f1_macro  \\\n",
       "0  {\"classifier__C\": 10.0, \"classifier__class_wei...                0.999897   \n",
       "1  {\"classifier__C\": 10.0, \"classifier__class_wei...                0.999908   \n",
       "2  {\"classifier__C\": 10.0, \"classifier__class_wei...                0.999827   \n",
       "3  {\"classifier__C\": 10.0, \"classifier__class_wei...                0.999805   \n",
       "\n",
       "   test_accuracy  test_precision_macro  test_recall_macro  test_f1_macro  \n",
       "0       0.999894              0.999907           0.999876       0.999892  \n",
       "1       0.999915              0.999926           0.999901       0.999913  \n",
       "2       0.999809              0.999827           0.999783       0.999805  \n",
       "3       0.999809              0.999833           0.999777       0.999805  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Directory to save evaluation results for tuned logistic regression\n",
    "results_dir = Path(\"results_logreg_tuned\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def build_logreg_pipeline(X_sample):\n",
    "    \"\"\"\n",
    "    Build a preprocessing + logistic regression pipeline based on the dtypes of X_sample.\n",
    "\n",
    "    Numeric columns: standardized with StandardScaler\n",
    "    Categorical columns: one-hot encoded with OneHotEncoder.\n",
    "    \"\"\"\n",
    "    numeric_cols = X_sample.select_dtypes(include=[\"number\", \"bool\"]).columns.tolist()\n",
    "    categorical_cols = X_sample.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    numeric_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    model = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Hyperparameter grid for logistic regression\n",
    "param_grid = {\n",
    "    \"classifier__C\": [0.1, 1.0, 10.0],\n",
    "    \"classifier__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "# Feature set names to evaluate\n",
    "feature_set_names = [\n",
    "    \"all_features\",\n",
    "    \"features_without_targets\",\n",
    "    \"selected_features\",\n",
    "    \"selected_features_without_targets\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "total_sets = len(feature_set_names)\n",
    "bar_len = 20\n",
    "\n",
    "for idx, name in enumerate(feature_set_names, start=1):\n",
    "    # Simple text progress bar for current feature set\n",
    "    filled = int(bar_len * idx / total_sets)\n",
    "    bar = \"[\" + \"#\" * filled + \"-\" * (bar_len - filled) + \"]\"\n",
    "    print(f\"\\n{bar} {idx}/{total_sets}  feature_set = {name}\")\n",
    "\n",
    "    # Get train/test data for this feature set\n",
    "    X_train, y_train, X_test, y_test = get_data(name)\n",
    "\n",
    "    # Build the base pipeline\n",
    "    base_model = build_logreg_pipeline(X_train)\n",
    "\n",
    "    # Grid search with 3-fold cross-validation using macro F1 as the scoring metric\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "        scoring=\"f1_macro\",\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Fit grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Convert full CV results to DataFrame\n",
    "    cv_results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "    # Save the full CV table for this feature set (for later use in the report)\n",
    "    cv_results_path = results_dir / f\"logreg_cv_results_{name}.csv\"\n",
    "    cv_results_df.to_csv(cv_results_path, index=False)\n",
    "\n",
    "    # Create a compact table showing (C, class_weight, mean_test_score)\n",
    "    short_table = cv_results_df[\n",
    "        [\n",
    "            \"param_classifier__C\",\n",
    "            \"param_classifier__class_weight\",\n",
    "            \"mean_test_score\",\n",
    "            \"std_test_score\",\n",
    "        ]\n",
    "    ].sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "    print(\"CV results (sorted by mean_test_score):\")\n",
    "    print(short_table.to_string(index=False))\n",
    "\n",
    "    # Use the best estimator to predict on the test set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Compute evaluation metrics on the test set\n",
    "    metrics = {\n",
    "        \"feature_set\": name,\n",
    "        \"best_params\": json.dumps(grid_search.best_params_),\n",
    "        \"cv_best_score_f1_macro\": grid_search.best_score_,\n",
    "        \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"test_precision_macro\": precision_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"test_recall_macro\": recall_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"test_f1_macro\": f1_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "    }\n",
    "    results.append(metrics)\n",
    "\n",
    "    print(\"Best params:\", grid_search.best_params_)\n",
    "    print(\n",
    "        \"Test metrics -> \"\n",
    "        f\"accuracy: {metrics['test_accuracy']:.6f}, \"\n",
    "        f\"precision_macro: {metrics['test_precision_macro']:.6f}, \"\n",
    "        f\"recall_macro: {metrics['test_recall_macro']:.6f}, \"\n",
    "        f\"f1_macro: {metrics['test_f1_macro']:.6f}\"\n",
    "    )\n",
    "\n",
    "# Collect all results into a DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(results_dir / \"logreg_tuned_feature_sets_metrics.csv\", index=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58470404-509b-453f-b98a-e806ffdfc207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188636, 52)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e248eed9-f6b7-472a-8620-85a2e2b1242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[#####---------------] 1/4  feature_set = all_features\n",
      "CV results for Random Forest (sorted by mean_test_score):\n",
      " param_classifier__n_estimators param_classifier__max_depth  param_classifier__min_samples_leaf  mean_test_score  std_test_score\n",
      "                            100                        None                                   1         0.999973    7.655545e-06\n",
      "                            300                        None                                   1         0.999968    1.325957e-05\n",
      "                            100                          20                                   1         0.999968    1.325957e-05\n",
      "                            300                          20                                   1         0.999962    1.531108e-05\n",
      "                            300                          20                                   5         0.999946    2.025540e-05\n",
      "                            100                        None                                   5         0.999946    2.025540e-05\n",
      "                            300                        None                                   5         0.999940    2.760349e-05\n",
      "                            100                          20                                   5         0.999930    2.025574e-05\n",
      "                            300                          10                                   1         0.999919    8.133598e-10\n",
      "                            300                          10                                   5         0.999913    7.656644e-06\n",
      "                            100                          10                                   1         0.999897    3.337051e-05\n",
      "                            100                          10                                   5         0.999865    2.760393e-05\n",
      "Best params: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 100}\n",
      "Test metrics -> accuracy: 0.999979, precision_macro: 0.999981, recall_macro: 0.999975, f1_macro: 0.999978\n",
      "\n",
      "[##########----------] 2/4  feature_set = features_without_targets\n",
      "CV results for Random Forest (sorted by mean_test_score):\n",
      " param_classifier__n_estimators param_classifier__max_depth  param_classifier__min_samples_leaf  mean_test_score  std_test_score\n",
      "                            300                        None                                   1         0.999962        0.000015\n",
      "                            300                          20                                   5         0.999957        0.000020\n",
      "                            300                          20                                   1         0.999957        0.000020\n",
      "                            100                        None                                   1         0.999951        0.000013\n",
      "                            100                          20                                   1         0.999951        0.000013\n",
      "                            300                        None                                   5         0.999951        0.000027\n",
      "                            100                          20                                   5         0.999946        0.000028\n",
      "                            100                        None                                   5         0.999935        0.000027\n",
      "                            300                          10                                   5         0.999924        0.000008\n",
      "                            300                          10                                   1         0.999908        0.000008\n",
      "                            100                          10                                   1         0.999859        0.000050\n",
      "                            100                          10                                   5         0.999838        0.000035\n",
      "Best params: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 300}\n",
      "Test metrics -> accuracy: 1.000000, precision_macro: 1.000000, recall_macro: 1.000000, f1_macro: 1.000000\n",
      "\n",
      "[###############-----] 3/4  feature_set = selected_features\n",
      "CV results for Random Forest (sorted by mean_test_score):\n",
      " param_classifier__n_estimators param_classifier__max_depth  param_classifier__min_samples_leaf  mean_test_score  std_test_score\n",
      "                            300                          20                                   1         0.999913        0.000028\n",
      "                            100                        None                                   1         0.999913        0.000020\n",
      "                            300                        None                                   1         0.999913        0.000020\n",
      "                            100                          20                                   1         0.999886        0.000027\n",
      "                            300                        None                                   5         0.999821        0.000027\n",
      "                            100                        None                                   5         0.999767        0.000033\n",
      "                            300                          20                                   5         0.999718        0.000033\n",
      "                            100                          20                                   5         0.999610        0.000106\n",
      "                            100                          10                                   1         0.998879        0.000200\n",
      "                            300                          10                                   1         0.998825        0.000175\n",
      "                            300                          10                                   5         0.998695        0.000080\n",
      "                            100                          10                                   5         0.998592        0.000385\n",
      "Best params: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 300}\n",
      "Test metrics -> accuracy: 0.999830, precision_macro: 0.999852, recall_macro: 0.999802, f1_macro: 0.999827\n",
      "\n",
      "[####################] 4/4  feature_set = selected_features_without_targets\n",
      "CV results for Random Forest (sorted by mean_test_score):\n",
      " param_classifier__n_estimators param_classifier__max_depth  param_classifier__min_samples_leaf  mean_test_score  std_test_score\n",
      "                            300                        None                                   1         0.999913        0.000033\n",
      "                            100                        None                                   1         0.999913        0.000020\n",
      "                            300                          20                                   1         0.999908        0.000020\n",
      "                            100                          20                                   1         0.999903        0.000013\n",
      "                            300                        None                                   5         0.999881        0.000015\n",
      "                            300                          20                                   5         0.999843        0.000020\n",
      "                            100                        None                                   5         0.999783        0.000047\n",
      "                            100                          20                                   5         0.999691        0.000081\n",
      "                            300                          10                                   1         0.999253        0.000301\n",
      "                            300                          10                                   5         0.998982        0.000339\n",
      "                            100                          10                                   1         0.998814        0.000265\n",
      "                            100                          10                                   5         0.998565        0.000390\n",
      "Best params: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 300}\n",
      "Test metrics -> accuracy: 0.999852, precision_macro: 0.999870, recall_macro: 0.999827, f1_macro: 0.999848\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_set</th>\n",
       "      <th>best_params</th>\n",
       "      <th>cv_best_score_f1_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_features</td>\n",
       "      <td>{\"classifier__max_depth\": null, \"classifier__m...</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>features_without_targets</td>\n",
       "      <td>{\"classifier__max_depth\": null, \"classifier__m...</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>selected_features</td>\n",
       "      <td>{\"classifier__max_depth\": 20, \"classifier__min...</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.999827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>selected_features_without_targets</td>\n",
       "      <td>{\"classifier__max_depth\": null, \"classifier__m...</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999827</td>\n",
       "      <td>0.999848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature_set  \\\n",
       "0                       all_features   \n",
       "1           features_without_targets   \n",
       "2                  selected_features   \n",
       "3  selected_features_without_targets   \n",
       "\n",
       "                                         best_params  cv_best_score_f1_macro  \\\n",
       "0  {\"classifier__max_depth\": null, \"classifier__m...                0.999973   \n",
       "1  {\"classifier__max_depth\": null, \"classifier__m...                0.999962   \n",
       "2  {\"classifier__max_depth\": 20, \"classifier__min...                0.999913   \n",
       "3  {\"classifier__max_depth\": null, \"classifier__m...                0.999913   \n",
       "\n",
       "   test_accuracy  test_precision_macro  test_recall_macro  test_f1_macro  \n",
       "0       0.999979              0.999981           0.999975       0.999978  \n",
       "1       1.000000              1.000000           1.000000       1.000000  \n",
       "2       0.999830              0.999852           0.999802       0.999827  \n",
       "3       0.999852              0.999870           0.999827       0.999848  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Directory to save evaluation results for tuned random forest\n",
    "results_dir_rf = Path(\"results_rf_tuned\")\n",
    "results_dir_rf.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def build_rf_pipeline(X_sample):\n",
    "    \"\"\"\n",
    "    Build a preprocessing + random forest pipeline based on the dtypes of X_sample.\n",
    "\n",
    "    Numeric columns: passed through without scaling (random forest is scale-invariant).\n",
    "    Categorical columns: one-hot encoded with OneHotEncoder.\n",
    "    \"\"\"\n",
    "    numeric_cols = X_sample.select_dtypes(include=[\"number\", \"bool\"]).columns.tolist()\n",
    "    categorical_cols = X_sample.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    # For random forest, numeric features do not need scaling, so we use \"passthrough\"\n",
    "    numeric_transformer = \"passthrough\"\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "    model = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Hyperparameter grid for random forest\n",
    "param_grid_rf = {\n",
    "    \"classifier__n_estimators\": [100, 300],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_leaf\": [1, 5],\n",
    "}\n",
    "\n",
    "# Feature set names to evaluate (same as for logistic regression)\n",
    "feature_set_names = [\n",
    "    \"all_features\",\n",
    "    \"features_without_targets\",\n",
    "    \"selected_features\",\n",
    "    \"selected_features_without_targets\",\n",
    "]\n",
    "\n",
    "rf_results = []\n",
    "total_sets = len(feature_set_names)\n",
    "bar_len = 20\n",
    "\n",
    "for idx, name in enumerate(feature_set_names, start=1):\n",
    "    # Simple text progress bar for current feature set\n",
    "    filled = int(bar_len * idx / total_sets)\n",
    "    bar = \"[\" + \"#\" * filled + \"-\" * (bar_len - filled) + \"]\"\n",
    "    print(f\"\\n{bar} {idx}/{total_sets}  feature_set = {name}\")\n",
    "\n",
    "    # Get train/test data for this feature set\n",
    "    X_train, y_train, X_test, y_test = get_data(name)\n",
    "\n",
    "    # Build the base pipeline\n",
    "    base_model = build_rf_pipeline(X_train)\n",
    "\n",
    "    # Grid search with 3-fold cross-validation using macro F1 as the scoring metric\n",
    "    grid_search_rf = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grid_rf,\n",
    "        cv=3,\n",
    "        scoring=\"f1_macro\",\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Fit grid search on the training data\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Convert full CV results to DataFrame\n",
    "    cv_results_rf_df = pd.DataFrame(grid_search_rf.cv_results_)\n",
    "\n",
    "    # Save the full CV table for this feature set (for later use in the report)\n",
    "    cv_results_path = results_dir_rf / f\"rf_cv_results_{name}.csv\"\n",
    "    cv_results_rf_df.to_csv(cv_results_path, index=False)\n",
    "\n",
    "    # Create a compact table showing (n_estimators, max_depth, min_samples_leaf, mean_test_score)\n",
    "    short_table_rf = cv_results_rf_df[\n",
    "        [\n",
    "            \"param_classifier__n_estimators\",\n",
    "            \"param_classifier__max_depth\",\n",
    "            \"param_classifier__min_samples_leaf\",\n",
    "            \"mean_test_score\",\n",
    "            \"std_test_score\",\n",
    "        ]\n",
    "    ].sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "    print(\"CV results for Random Forest (sorted by mean_test_score):\")\n",
    "    print(short_table_rf.to_string(index=False))\n",
    "\n",
    "    # Use the best estimator to predict on the test set\n",
    "    best_rf_model = grid_search_rf.best_estimator_\n",
    "    y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "    # Compute evaluation metrics on the test set\n",
    "    metrics_rf = {\n",
    "        \"feature_set\": name,\n",
    "        \"best_params\": json.dumps(grid_search_rf.best_params_),\n",
    "        \"cv_best_score_f1_macro\": grid_search_rf.best_score_,\n",
    "        \"test_accuracy\": accuracy_score(y_test, y_pred_rf),\n",
    "        \"test_precision_macro\": precision_score(y_test, y_pred_rf, average=\"macro\", zero_division=0),\n",
    "        \"test_recall_macro\": recall_score(y_test, y_pred_rf, average=\"macro\", zero_division=0),\n",
    "        \"test_f1_macro\": f1_score(y_test, y_pred_rf, average=\"macro\", zero_division=0),\n",
    "    }\n",
    "    rf_results.append(metrics_rf)\n",
    "\n",
    "    print(\"Best params:\", grid_search_rf.best_params_)\n",
    "    print(\n",
    "        \"Test metrics -> \"\n",
    "        f\"accuracy: {metrics_rf['test_accuracy']:.6f}, \"\n",
    "        f\"precision_macro: {metrics_rf['test_precision_macro']:.6f}, \"\n",
    "        f\"recall_macro: {metrics_rf['test_recall_macro']:.6f}, \"\n",
    "        f\"f1_macro: {metrics_rf['test_f1_macro']:.6f}\"\n",
    "    )\n",
    "\n",
    "# Collect all random forest results into a DataFrame and save to CSV\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "rf_results_df.to_csv(results_dir_rf / \"rf_tuned_feature_sets_metrics.csv\", index=False)\n",
    "rf_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a2e8f-aa44-47e6-be30-47effa543ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
